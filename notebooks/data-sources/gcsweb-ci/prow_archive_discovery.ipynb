{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84450e02",
   "metadata": {},
   "source": [
    "# Prow Logs and GCS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2b17c",
   "metadata": {},
   "source": [
    "### What do we have access to as data scientists when digging into the build artifacts?\n",
    "\n",
    "In this notebook we will demonstrate how to discover and interact with the data (logs) made availble on [GCS/origin-ci-test](https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/) as well as provide some simple EDA to help folks get started analyzing this data.\n",
    "\n",
    "This notebook is divided into 2 sections:\n",
    "\n",
    "1. Compare the different log files present throughout the archives and quantify how complete and comparable our log dataset is from build to build.\n",
    "1. Download a sample dataset of the events and build logs to perform some lite EDA.\n",
    "\n",
    "_Note: We will be collecting data from the \"origin-ci-test\" Bucket on Google Cloud Storage. But, after some out-of-notebook exploration it has become aparent that this is a massive amount of data that contains more than just the OpenShift CI logs we are intrested in here and programatically investigating that Bucket is not advised. Therefore, we recommend using the [web ui](https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/) to inspect what jobs are exposed and identify what is of interest to your analysis before collecting data via the google cloud stporage api. Here we will rely on web-scraping the UI to explore what's available to us based on what jobs are displayed on [TestGrid](https://testgrid.k8s.io/redhat-assisted-installer)._     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e7580",
   "metadata": {},
   "source": [
    "## Compare availability of log files across a build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eb5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from google.cloud import storage\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ae7eb",
   "metadata": {},
   "source": [
    "### Example to access a single set of Prow artifacts\n",
    "\n",
    "Let's make sure we understand how this works, and focus on a single job first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df335d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = '\"redhat-openshift-ocp-release-4.6-informing\"'\n",
    "job = \"periodic-ci-openshift-release-master-ci-4.6-upgrade-from-stable-4.5-e2e-gcp-upgrade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2796a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    f\"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/{job}\"\n",
    ")\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "list_of_builds = [x.get_text()[1:-1] for x in soup.find_all(\"a\")][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5781bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/periodic-ci-openshift-release-master-ci-4.6-upgrade-from-stable-4.5-e2e-gcp-upgrade/1364869749170769920'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\n",
    "    f\"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/{job}/{list_of_builds[1]}\"\n",
    ")\n",
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475853f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa2c7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ..',\n",
       " ' artifacts/',\n",
       " ' build-log.txt',\n",
       " ' finished.json',\n",
       " ' podinfo.json',\n",
       " ' prowjob.json',\n",
       " ' started.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.get_text() for x in soup.find_all(\"a\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a42e2",
   "metadata": {},
   "source": [
    "Great, we can now programmatically access the archives. Now, lets walk through all of the build archives for a single job and create a list of what they have on the first level of their directories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389751c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_data = {}\n",
    "\n",
    "for build in list_of_builds:\n",
    "    response = requests.get(\n",
    "        f\"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/{job}/{build}\"\n",
    "    )\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    artifacts = [x.get_text() for x in soup.find_all(\"a\")]\n",
    "    build_data[build] = artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20799616",
   "metadata": {},
   "outputs": [],
   "source": [
    "builds_info = pd.Series({k: len(v) for (k, v) in build_data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8d5eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    238\n",
       "6      3\n",
       "5      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builds_info.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d634d02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " ..  artifacts/  build-log.txt  finished.json  podinfo.json  prowjob.json  started.json    238\n",
       " ..  artifacts/  build-log.txt  finished.json  prowjob.json  started.json                    2\n",
       " ..  build-log.txt  finished.json  podinfo.json  prowjob.json  started.json                  1\n",
       " ..  build-log.txt  finished.json  prowjob.json  started.json                                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(build_data).apply(\" \".join).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef560849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.983471\n",
       "6    0.012397\n",
       "5    0.004132\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builds_info.value_counts() / len(builds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbf007",
   "metadata": {},
   "source": [
    "~98% percent of our records for this job appear to be complete and include the 'artifacts/' subdirectory, lets dig in and see what they contain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a0f0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_data = {}\n",
    "\n",
    "for build in list_of_builds:\n",
    "    response = requests.get(\n",
    "        f\"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/{job}/{build}/artifacts\"\n",
    "    )\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    artifacts = [x.get_text() for x in soup.find_all(\"a\")]\n",
    "    build_data[build] = artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab234df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    95\n",
       "8    58\n",
       "7    46\n",
       "5    36\n",
       "1     2\n",
       "3     2\n",
       "4     2\n",
       "2     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_info = pd.Series({k: len(v) for (k, v) in build_data.items()})\n",
    "artifact_info.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae6a9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    0.392562\n",
       "8    0.239669\n",
       "7    0.190083\n",
       "5    0.148760\n",
       "1    0.008264\n",
       "3    0.008264\n",
       "4    0.008264\n",
       "2    0.004132\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_info.value_counts() / len(artifact_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c85b4e",
   "metadata": {},
   "source": [
    "The above shows us that the there are about 40% of the artifacts dirs that have 6 items and 20% that have 7 or 8 (but it does not account for different combinations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67daa19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " ..  build-resources/  e2e-gcp-upgrade/  release/  junit_operator.xml  metadata.json                                                  0.380165\n",
       " ..  build-resources/  e2e-gcp-upgrade/  release/  ci-operator-step-graph.json  ci-operator.log  junit_operator.xml  metadata.json    0.239669\n",
       " ..  build-resources/  e2e-gcp-upgrade/  release/  ci-operator.log  junit_operator.xml  metadata.json                                 0.161157\n",
       " ..  build-resources/  e2e-gcp-upgrade/  junit_operator.xml  metadata.json                                                            0.111570\n",
       " ..  build-resources/  release/  junit_operator.xml  metadata.json                                                                    0.037190\n",
       " ..  build-resources/  release/  ci-operator-step-graph.json  ci-operator.log  junit_operator.xml  metadata.json                      0.028926\n",
       " ..  build-resources/  release/  ci-operator.log  junit_operator.xml  metadata.json                                                   0.008264\n",
       " ..  build-resources/  junit_operator.xml  metadata.json                                                                              0.008264\n",
       " ..                                                                                                                                   0.008264\n",
       " ..  junit_job.xml                                                                                                                    0.004132\n",
       " ..  junit_job.xml  metadata.json                                                                                                     0.004132\n",
       " ..  build-resources/  e2e-gcp-upgrade/  release/  ci-operator.log  metadata.json                                                     0.004132\n",
       " ..  e2e-gcp-upgrade/  release/                                                                                                       0.004132\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(build_data).apply(\" \".join).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59947e",
   "metadata": {},
   "source": [
    "We can see from the results above that once we get down into the artifacts there is a far less uniformity to the data available to us for analysis. And this is all within a single job! Moving forward we will assume that this issue gets worse when comparing available artifacts across jobs and can dedicate a later notebook to proving out that assumption.  \n",
    "\n",
    "This heterogeneity of objects available for each build will make it somewhat difficult to use these sets of documents as a whole to compare different CI behaviour. At this point, it makes sense to consider looking only at the same document (log) across job where available. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ea321",
   "metadata": {},
   "source": [
    "## Collect Data\n",
    "\n",
    "### Build logs\n",
    "\n",
    "In the next section we are going to walkthrough accessing the `build-logs.txt` and the `events.json` as they appear to be nearly universally available. We will both download a small testing dataset as well show how to work directly with the data in memory.\n",
    "\n",
    "Now that we know what logs we want to collect its simpler to use the google cloud storage api to access or data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b22122ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_storage(bucket_name):\n",
    "    storage_client = storage.Client.create_anonymous_client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    return {\"bucket\": bucket, \"storage_client\": storage_client}\n",
    "\n",
    "\n",
    "def download_public_file(client, source_blob_name):\n",
    "    \"\"\"Downloads a public blob from the bucket.\"\"\"\n",
    "    blob = client[\"bucket\"].blob(source_blob_name)\n",
    "    if blob.exists(client[\"storage_client\"]):\n",
    "        text = blob.download_as_text()\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33215d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_connection = connect_storage(\"origin-ci-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f19b7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into memory\n",
    "build_log_data = {}\n",
    "for build in list_of_builds:\n",
    "    file = download_public_file(bucket_connection, f\"logs/{job}/{build}/build-log.txt\")\n",
    "    build_log_data[build] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80a31a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021/02/25 03:27:14 ci-operator version v20210224-231f07b\\n2021/02/25 03:27:14 Loading configuration from https://config.ci.openshift.org for openshift/release@master [ci-4.6-upgrade-from-stable-4.5]\\nerror: failed to load configuration: got unexpected http 404 status code from configresolver: failed to get config: could not find any config for branch master on repo openshift/release\\ntime=\"2021-02-25T03:27:14Z\" level=info msg=\"Reporting job state \\'failed\\' with reason \\'loading_args:loading_config:config_resolver\\'\"\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_log_data[list(build_log_data.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8e401d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(x):\n",
    "    \"\"\"\n",
    "    Gets counts for chars, words, lines for a log.\n",
    "    \"\"\"\n",
    "    if x:\n",
    "        chars = len(x)\n",
    "        words = len(x.split())\n",
    "        lines = x.count(\"\\n\") + 1\n",
    "        return chars, words, lines\n",
    "    else:\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ddd930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>build_log_id</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1364778930069835776</td>\n",
       "      <td>517</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1364869749170769920</td>\n",
       "      <td>10805</td>\n",
       "      <td>919</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1364960659313266688</td>\n",
       "      <td>10807</td>\n",
       "      <td>919</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1365051265100288000</td>\n",
       "      <td>15758</td>\n",
       "      <td>1316</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1365142142841786368</td>\n",
       "      <td>10804</td>\n",
       "      <td>919</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1386232963561164800</td>\n",
       "      <td>16674</td>\n",
       "      <td>1166</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1386323699170283520</td>\n",
       "      <td>16954</td>\n",
       "      <td>1189</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1386414426231410688</td>\n",
       "      <td>16673</td>\n",
       "      <td>1167</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1386505145390469120</td>\n",
       "      <td>16674</td>\n",
       "      <td>1167</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1386595860728516608</td>\n",
       "      <td>16953</td>\n",
       "      <td>1189</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            build_log_id  chars  words  lines\n",
       "0    1364778930069835776    517     51      5\n",
       "1    1364869749170769920  10805    919    111\n",
       "2    1364960659313266688  10807    919    111\n",
       "3    1365051265100288000  15758   1316    184\n",
       "4    1365142142841786368  10804    919    111\n",
       "..                   ...    ...    ...    ...\n",
       "237  1386232963561164800  16674   1166    120\n",
       "238  1386323699170283520  16954   1189    120\n",
       "239  1386414426231410688  16673   1167    120\n",
       "240  1386505145390469120  16674   1167    120\n",
       "241  1386595860728516608  16953   1189    120\n",
       "\n",
       "[242 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a dataframe with char, words, and lines\n",
    "## count for the logs\n",
    "data = []\n",
    "for key, value in build_log_data.items():\n",
    "    chars, words, lines = get_counts(value)\n",
    "    data.append([key, chars, words, lines])\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"build_log_id\", \"chars\", \"words\", \"lines\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e39fa",
   "metadata": {},
   "source": [
    "#### See the stats for chars, words, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92e76008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.420000e+02\n",
       "mean     1.805198e+05\n",
       "std      8.681102e+05\n",
       "min      9.200000e+01\n",
       "25%      1.084125e+04\n",
       "50%      1.122550e+04\n",
       "75%      1.675175e+04\n",
       "max      6.662932e+06\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"chars\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64db4de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       242.000000\n",
       "mean      12469.330579\n",
       "std       60873.841513\n",
       "min          11.000000\n",
       "25%         919.000000\n",
       "50%         926.000000\n",
       "75%        1201.750000\n",
       "max      508998.000000\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"words\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c98b74f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      242.000000\n",
       "mean       722.760331\n",
       "std       3001.253363\n",
       "min          2.000000\n",
       "25%        111.000000\n",
       "50%        113.000000\n",
       "75%        120.000000\n",
       "max      21291.000000\n",
       "Name: lines, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lines\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd10988",
   "metadata": {},
   "source": [
    "From the initial analysis above, we see that we have log files with 2 lines to ~21,000 lines with a mean of ~720 lines. This suggests high variability. The next thing we could look at would be the similarity betwen the log files, performing word analysis, templating, and clustering. We will address those questions in an upcoming notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c64849",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb64d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_events_data = {}\n",
    "for build in list_of_builds:\n",
    "    file = download_public_file(\n",
    "        bucket_connection, f\"logs/{job}/{build}/artifacts/build-resources/events.json\"\n",
    "    )\n",
    "    if file:\n",
    "        build_events_data[build] = json.loads(file)\n",
    "    else:\n",
    "        build_events_data[build] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fba810d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.93388429752066"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Percentage of builds that have the events.json file\n",
    "count = 0\n",
    "for key, value in build_events_data.items():\n",
    "    if value:\n",
    "        count += 1\n",
    "count * 100 / len(build_events_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a9e67e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>504b881c-9e97-46a0-b206-765c9973e1d3</td>\n",
       "      <td>Running job periodic-ci-openshift-release-mast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3a92467e-993e-43a1-8eee-24ba7a22508f</td>\n",
       "      <td>Running job periodic-ci-openshift-release-mast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ed40875c-b182-4164-b730-a3754ed94124</td>\n",
       "      <td>Running job periodic-ci-openshift-release-mast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b8c5b026-936e-4f28-a0de-62051ff378d8</td>\n",
       "      <td>Running job periodic-ci-openshift-release-mast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b8265a-d87d-430d-b38e-c10c7f3fb91c</td>\n",
       "      <td>No matching pods found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>db97f7b5-5fb4-4e68-aa82-cd9c120b9c8d</td>\n",
       "      <td>Container image \"gcr.io/k8s-prow/sidecar:v2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>947a5c3f-f318-42d8-88c5-133f9783e94d</td>\n",
       "      <td>Created container sidecar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>e94e0988-c2ea-4045-bb84-251410018d94</td>\n",
       "      <td>Started container sidecar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>00bef865-7965-4b65-b39a-9993347c5942</td>\n",
       "      <td>Back-off pulling image \"image-registry.openshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>a85f8fbd-9cac-4e47-a5d4-5fbe145d4050</td>\n",
       "      <td>Error: ImagePullBackOff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      UID  \\\n",
       "0    504b881c-9e97-46a0-b206-765c9973e1d3   \n",
       "1    3a92467e-993e-43a1-8eee-24ba7a22508f   \n",
       "2    ed40875c-b182-4164-b730-a3754ed94124   \n",
       "3    b8c5b026-936e-4f28-a0de-62051ff378d8   \n",
       "4    b1b8265a-d87d-430d-b38e-c10c7f3fb91c   \n",
       "..                                    ...   \n",
       "477  db97f7b5-5fb4-4e68-aa82-cd9c120b9c8d   \n",
       "478  947a5c3f-f318-42d8-88c5-133f9783e94d   \n",
       "479  e94e0988-c2ea-4045-bb84-251410018d94   \n",
       "480  00bef865-7965-4b65-b39a-9993347c5942   \n",
       "481  a85f8fbd-9cac-4e47-a5d4-5fbe145d4050   \n",
       "\n",
       "                                               message  \n",
       "0    Running job periodic-ci-openshift-release-mast...  \n",
       "1    Running job periodic-ci-openshift-release-mast...  \n",
       "2    Running job periodic-ci-openshift-release-mast...  \n",
       "3    Running job periodic-ci-openshift-release-mast...  \n",
       "4                               No matching pods found  \n",
       "..                                                 ...  \n",
       "477  Container image \"gcr.io/k8s-prow/sidecar:v2021...  \n",
       "478                          Created container sidecar  \n",
       "479                          Started container sidecar  \n",
       "480  Back-off pulling image \"image-registry.openshi...  \n",
       "481                            Error: ImagePullBackOff  \n",
       "\n",
       "[482 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing the messages of a single build\n",
    "messages = [\n",
    "    (i[\"metadata\"][\"uid\"], i[\"message\"])\n",
    "    for i in build_events_data[\"1364869749170769920\"][\"items\"]\n",
    "]\n",
    "messages_df = pd.DataFrame(messages, columns=[\"UID\", \"message\"])\n",
    "messages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7f4ca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                   482\n",
       "unique                                                  156\n",
       "top       Container image \"gcr.io/k8s-prow/entrypoint:v2...\n",
       "freq                                                     29\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df[\"message\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e438c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Container image \"gcr.io/k8s-prow/entrypoint:v2...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Started container place-entrypoint</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Container image \"gcr.io/k8s-prow/sidecar:v2021...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Started container sidecar</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Created container place-entrypoint</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Successfully pulled image \"image-registry.open...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>found no controller ref for pod \"e2e-gcp-upgra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Successfully assigned ci-op-ft9klqc6/e2e-azure...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Successfully pulled image \"registry.ci.openshi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Failed to calculate the number of expected pod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 index  message\n",
       "0    Container image \"gcr.io/k8s-prow/entrypoint:v2...       29\n",
       "1                   Started container place-entrypoint       29\n",
       "2    Container image \"gcr.io/k8s-prow/sidecar:v2021...       29\n",
       "3                            Started container sidecar       29\n",
       "4                   Created container place-entrypoint       29\n",
       "..                                                 ...      ...\n",
       "151  Successfully pulled image \"image-registry.open...        1\n",
       "152  found no controller ref for pod \"e2e-gcp-upgra...        1\n",
       "153  Successfully assigned ci-op-ft9klqc6/e2e-azure...        1\n",
       "154  Successfully pulled image \"registry.ci.openshi...        1\n",
       "155  Failed to calculate the number of expected pod...        1\n",
       "\n",
       "[156 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df[\"message\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c3cd1",
   "metadata": {},
   "source": [
    "In the build data, we saw that about ~97% builds have the events.json file. We further analyzed all the events that happened for a particular build and found the frequencies of the messages. We can repeat the process for all the other builds and find most common messages and perform further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa4f26",
   "metadata": {},
   "source": [
    "# Save sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8176a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../data/raw/gcs/build-logs/\"\n",
    "filename = \"sample-build-logs.parquet\"\n",
    "dataset_base_path = Path(path)\n",
    "dataset_base_path.mkdir(parents=True, exist_ok=True)\n",
    "build_logs = pd.DataFrame.from_dict(build_log_data, orient=\"index\", columns=[\"log\"])\n",
    "build_logs.to_parquet(f\"{path}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc86d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../data/raw/gcs/events/\"\n",
    "filename = \"sample-events.json\"\n",
    "dataset_base_path = Path(path)\n",
    "dataset_base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(f\"{path}/{filename}\", \"w\") as file:\n",
    "    json.dump(build_events_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790331a4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to programmatically access the gcs openshift origins ci archives, pull specific logs types into our notebook for analysis and save them for later use. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
